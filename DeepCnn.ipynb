{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irSzZyka_5mZ",
        "outputId": "3b3c51f1-de9a-4f96-869c-6adab6773c8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Found 12000 images belonging to 50 classes.\n",
            "Found 3000 images belonging to 50 classes.\n",
            "Epoch 1/10\n",
            "375/375 [==============================] - ETA: 0s - loss: 2.7709 - accuracy: 0.2722"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3000 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r375/375 [==============================] - 574s 2s/step - loss: 2.7709 - accuracy: 0.2722 - val_loss: 1.2370 - val_accuracy: 0.6460\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 118s 315ms/step - loss: 1.4629 - accuracy: 0.5817\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 118s 314ms/step - loss: 1.1692 - accuracy: 0.6575\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 121s 321ms/step - loss: 1.0134 - accuracy: 0.6968\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 119s 315ms/step - loss: 0.9469 - accuracy: 0.7175\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 117s 312ms/step - loss: 0.8445 - accuracy: 0.7448\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 116s 310ms/step - loss: 0.8056 - accuracy: 0.7593\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 117s 311ms/step - loss: 0.7355 - accuracy: 0.7778\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 121s 323ms/step - loss: 0.6951 - accuracy: 0.7848\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 117s 312ms/step - loss: 0.6744 - accuracy: 0.7958\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 38, 38, 128)       3584      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 19, 19, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 19, 19, 128)       0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 17, 17, 64)        73792     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               524416    \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 50)                6450      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 608,242\n",
            "Trainable params: 608,242\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Saved model to disk\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu', input_shape = (40, 40, 3)))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "classifier.add(Dropout(.2))\n",
        "\n",
        "classifier.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "classifier.add(Dropout(.2))\n",
        "\n",
        "classifier.add(Flatten())\n",
        "\n",
        "classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "classifier.add(Dropout(.2))\n",
        "\n",
        "classifier.add(Dense(units = 50, activation = 'softmax'))\n",
        "\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import ImageFile\n",
        "from google.colab import drive\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = .2, rotation_range = 25)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/gdrive/MyDrive/dataset/Train', target_size = (40, 40),\n",
        "                                                 batch_size = 32, class_mode = 'categorical')\n",
        "test_set = test_datagen.flow_from_directory('/content/gdrive/MyDrive/dataset/Test', target_size = (40, 40),\n",
        "                                                 batch_size = 32, class_mode = 'categorical')\n",
        "\n",
        "\n",
        "classifier.fit(training_set, steps_per_epoch=375, epochs=10, validation_data=test_set, validation_steps=3000)\n",
        "\n",
        "\n",
        "\n",
        "classifier.summary()\n",
        "\n",
        "classifier_json = classifier.to_json()\n",
        "\n",
        "with open(\"CNN_BanglaHandWrittenCharacterRecognition.json\", \"w\") as json_file:\n",
        "    json_file.write(classifier_json)\n",
        "\n",
        "classifier.save_weights(\"CNN_BanglaHandWrittenCharacterRecognition.h5\")\n",
        "print('Saved model to disk')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting the CNN model to the Dataset"
      ],
      "metadata": {
        "id": "n8n7TeyeAMvr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ecnFlfpoY-0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "from PIL import ImageTk, ImageDraw, Image\n",
        "from tkinter import *\n",
        "from keras.preprocessing import image\n",
        "import os\n",
        "\n",
        "\n",
        "def create_new_image():\n",
        "    width = 256\n",
        "    height = 256\n",
        "    center = height // 2\n",
        "    white = (255, 255, 255)\n",
        "    green = (0, 128, 0)\n",
        "\n",
        "    def save():\n",
        "        filename = 'C:/Users/MHB/Desktop/BHWCC/Dataset/SinglePrediction/image.jpg'\n",
        "        image.save(filename)\n",
        "\n",
        "    def paint(event):\n",
        "        x1, y1 = (event.x - 1), (event.y - 1)\n",
        "        x2, y2 = (event.x + 1), (event.y + 1)\n",
        "        cv.create_oval(x1, y1, x2, y2, fill = 'black', width = 30)\n",
        "        draw.line([x1, y1, x2, y2], fill = 'black', width = 30)\n",
        "\n",
        "    root = Tk()\n",
        "\n",
        "    cv = Canvas(root, width = width, height = height, bg = 'white')\n",
        "    cv.pack()\n",
        "\n",
        "    image = PIL.Image.new('RGB', (width, height), white)\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    cv.pack(expand = YES, fill = BOTH)\n",
        "    cv.bind(\"<B1-Motion>\", paint)\n",
        "\n",
        "    button = Button(text = 'Save', command = save)\n",
        "    button.pack()\n",
        "\n",
        "    root.mainloop()\n",
        "\n",
        "\n",
        "def determine_character(res):\n",
        "    if res == 0:\n",
        "        print('prediction : অ')\n",
        "    elif res == 1:\n",
        "        print('prediction : আ')\n",
        "    elif res == 2:\n",
        "        print('prediction : ই')\n",
        "    elif res == 3:\n",
        "        print('prediction : ঈ')\n",
        "    elif res == 4:\n",
        "        print('prediction : উ')\n",
        "    elif res == 5:\n",
        "        print('prediction : ঊ')\n",
        "    elif res == 6:\n",
        "        print('prediction : ঋ')\n",
        "    elif res == 7:\n",
        "        print('prediction : এ')\n",
        "    elif res == 8:\n",
        "        print('prediction : ঐ')\n",
        "    elif res == 9:\n",
        "        print('prediction : ও')\n",
        "    elif res == 10:\n",
        "        print('prediction : ঔ')\n",
        "    elif res == 11:\n",
        "        print('prediction : ক')\n",
        "    elif res == 12:\n",
        "        print('prediction : খ')\n",
        "    elif res == 13:\n",
        "        print('prediction : গ')\n",
        "    elif res == 14:\n",
        "        print('prediction : ঘ')\n",
        "    elif res == 15:\n",
        "        print('prediction : ঙ')\n",
        "    elif res == 16:\n",
        "        print('prediction : চ')\n",
        "    elif res == 17:\n",
        "        print('prediction : ছ')\n",
        "    elif res == 18:\n",
        "        print('prediction : জ')\n",
        "    elif res == 19:\n",
        "        print('prediction : ঝ')\n",
        "    elif res == 20:\n",
        "        print('prediction : ঞ')\n",
        "    elif res == 21:\n",
        "        print('prediction : ট')\n",
        "    elif res == 22:\n",
        "        print('prediction : ঠ')\n",
        "    elif res == 23:\n",
        "        print('prediction : ড')\n",
        "    elif res == 24:\n",
        "        print('prediction : ঢ')\n",
        "    elif res == 25:\n",
        "        print('prediction : ণ')\n",
        "    elif res == 26:\n",
        "        print('prediction : ত')\n",
        "    elif res == 27:\n",
        "        print('prediction : থ')\n",
        "    elif res == 28:\n",
        "        print('prediction : দ')\n",
        "    elif res == 29:\n",
        "        print('prediction : ধ')\n",
        "    elif res == 30:\n",
        "        print('prediction : ন')\n",
        "    elif res == 31:\n",
        "        print('prediction : প')\n",
        "    elif res == 32:\n",
        "        print('prediction : ফ')\n",
        "    elif res == 33:\n",
        "        print('prediction : ব')\n",
        "    elif res == 34:\n",
        "        print('prediction : ভ')\n",
        "    elif res == 35:\n",
        "        print('prediction : ম')\n",
        "    elif res == 36:\n",
        "        print('prediction : য')\n",
        "    elif res == 37:\n",
        "        print('prediction : র')\n",
        "    elif res == 38:\n",
        "        print('prediction : ল')\n",
        "    elif res == 39:\n",
        "        print('prediction : শ')\n",
        "    elif res == 40:\n",
        "        print('prediction : ষ')\n",
        "    elif res == 41:\n",
        "        print('prediction : স')\n",
        "    elif res == 42:\n",
        "        print('prediction : হ')\n",
        "    elif res == 43:\n",
        "        print('prediction : ড়')\n",
        "    elif res == 44:\n",
        "        print('prediction : ঢ়')\n",
        "    elif res == 45:\n",
        "        print('prediction : য়')\n",
        "    elif res == 46:\n",
        "        print('prediction : ৎ')\n",
        "    elif res == 47:\n",
        "        print('prediction : ং')\n",
        "    elif res == 48:\n",
        "        print('prediction : ঃ')\n",
        "    else:\n",
        "        print('prediction : ঁ')"
      ],
      "metadata": {
        "id": "ozaoXm6hHg4R"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import ImageTk, ImageDraw, Image\n",
        "from tkinter import *\n",
        "from keras.preprocessing import image\n",
        "import os\n",
        "\n",
        "def single_prediction(test_img):\n",
        "    test_img_arr = image.img_to_array(test_img)\n",
        "    test_img_arr = np.expand_dims(test_img_arr, axis = 0)\n",
        "    prediction = classifier.predict(test_img_arr)\n",
        "    result = np.argmax(prediction, axis = 1)\n",
        "    determine_character(result)\n",
        "\n",
        "    def delete_created_image():\n",
        "       os.remove('C:/Users/MHB/Desktop/BHWCC/Dataset/SinglePrediction/image.jpg')\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "def draw_n_guess_the_character():\n",
        "    create_new_image()\n",
        "    test_img = image.load_img('C:/Users/MHB/Desktop/BHWCC/Dataset/SinglePrediction/image.jpg', target_size = (40, 40, 3))\n",
        "    single_prediction(test_img)\n",
        "    plt.imshow(test_img)\n",
        "    delete_created_image()\n",
        "\n",
        "\n",
        "\n",
        "    draw_n_guess_the_character()"
      ],
      "metadata": {
        "id": "wSQnPWoeqOh2"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}