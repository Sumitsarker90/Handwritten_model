{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwm-rhK5EcSQ",
        "outputId": "0ad5d660-be22-4b3f-a0b4-f13f1093414d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Found 12000 images belonging to 50 classes.\n",
            "Found 3000 images belonging to 50 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "375/375 [==============================] - 5538s 15s/step - loss: 3.8277 - accuracy: 0.0409 - val_loss: 3.7073 - val_accuracy: 0.0620\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 2957s 8s/step - loss: 3.6990 - accuracy: 0.0553 - val_loss: 3.5559 - val_accuracy: 0.0823\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 2918s 8s/step - loss: 3.6269 - accuracy: 0.0639 - val_loss: 3.4350 - val_accuracy: 0.1173\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 2909s 8s/step - loss: 3.5771 - accuracy: 0.0715 - val_loss: 3.3981 - val_accuracy: 0.1210\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 2890s 8s/step - loss: 3.5409 - accuracy: 0.0753 - val_loss: 3.2922 - val_accuracy: 0.1470\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 2873s 8s/step - loss: 3.5084 - accuracy: 0.0813 - val_loss: 3.2564 - val_accuracy: 0.1387\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 2852s 8s/step - loss: 3.4833 - accuracy: 0.0860 - val_loss: 3.2128 - val_accuracy: 0.1657\n",
            "Epoch 8/10\n",
            "190/375 [==============>...............] - ETA: 19:06 - loss: 3.4636 - accuracy: 0.0911"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Define dataset directory\n",
        "dataset_dir = '/content/gdrive/My Drive/dataset'\n",
        "\n",
        "# Configure GPU visibility\n",
        "tf.config.experimental.set_visible_devices([], 'GPU')\n",
        "\n",
        "# Define target size and batch size\n",
        "target_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# Load training data using ImageDataGenerator with augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    os.path.join(dataset_dir, 'Train'),\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "# Load test data using ImageDataGenerator\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    os.path.join(dataset_dir, 'Test'),\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "# Load ResNet-50 model with custom top layers\n",
        "base_model = ResNet50(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "\n",
        "# Add custom classification layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks for early stopping and model checkpointing\n",
        "early_stopping = EarlyStopping(patience=3, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('/content/gdrive/My Drive/best_model.h5', save_best_only=True)\n",
        "\n",
        "# Train the model with callbacks\n",
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_generator,\n",
        "    callbacks=[early_stopping, model_checkpoint]\n",
        ")\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {test_loss:.4f} - Test Accuracy: {test_accuracy:.4f}\")\n"
      ]
    }
  ]
}